# Solution Estimation

In this chapter, we describe the equation that gives an answer to finding the minimal
set of intervals $S_0=\{I_1,\dotsc, I_k\}$, and we also we explore the solutions
are implemented at the same time as giving some alternatives to simplify the search
path and find an approximate solution.

## Model Selection Criterion

We propose a method to estimate this minimal set of intervals $S_0=\{I_1,\dotsc, I_k\}$
by optimizing a criterion over all possible sets of intervals, namely

\begin{equation}\label{opprob}
\hat S \;=\; \underset{S}{\arg\max}\; \Bigl\{ \sum_{I\in S} ( \text{pen}({\X}_I)) \Bigr\}\,,
\end{equation}
where **lik* is a likelihood function of the ${\X}_I$ segment.

The solution so the equation is usually done with dynamic programming, however the
search path the algorithm takes might take a long time evaluating all the possible
combinations to give the best result, or might as well make some assumptions to
prune the search path and give an approximate result. A few alternatives are
explored.

## Exact Algorithm

The first attempt to try to solve the equation would be to actually search all the possible alternatives
in order to find the correct minimal set of intervals that maximize the total likelihood of the system.
It's done iteratively by:

- for each column index $i \in \{1, \dots, p\}$
- for each column index $j \in \{i, \dots, p\}$
- compute $l_{i:j}=\text{lik}(X_{i:j})$
- store the likelihood $l_{i:j}$ and the index $j$ for the highest value of $l_{i:j}$ for later comparison

Finally, after computing all of the possible combinations of likelihood segments,
the procedure to find the optimal solution would be as following:

- let $j = p$
- while $j > 1$, repeat the steps below
- search the stored values for $i = \underset{i}{\arg\max} (l_{i:j})$
- store $i$ in the set of change points $C$ if $i \ne 1$
- let $j = i$ and repeat until $j = 1$

Given the indices in the change points set $C$, let $c_0 = 1$, $c_{k+1}=p$ and $c_i\in C$
be the sequence of sorted elements of $C$, for $i = 1, \dots, k$. The minimal set of
intervals would be defined as $S_0 = \{ c_{i-1}:c_i, \text{ for } i=1,\dots,k+1 \}$
in which $c_{i-1}:c_i=\{\text{contiguous sequence of number from } c_{i-1} \text{ to } c_i\}$.

The described algorithm will provide the correct answer for the equation, precisely because it
analyses all the possible combinations. However, that has a time complexity in Big-O notation of
$O(np^2)$ in which $n$ is the number of samples in the data set and $p$ is the number of columns.
Because a lot of use cases for data segmentation has usually a large number of columns and not
many data samples, e.g. DNA data, computation time can be very prohibitive.

## Hierarchical Algorithm

In order to try to simplify the search path of the algorithm, [@base-paper] also proposes a technique
that relies on assuming the data to be hierarchical, i.e. it assumes the minimal solution set can
me estimated by only searching the data for the optimal change point segmentation once. The algorithm
is described below.

- let $d$ be the current data set we want to segment
- for each column $i$ in the data set
- compute the total likelihood $l_i = \text{lik}(X_{1:i-1})+\text{lik}(X_{i:p})$ if $i \ne 1$
- find $i$ for which $l_i$ is maximum
- if $l_i < \text{lik}(X_{1:p})$ return empty set as result of current function call
- recursively find the set of change points $C_L$ by calling the algorithm on the left segment $X_{1:i-1}$
- recursively find the set of change points $C_R$ by calling the algorithm on the right segment $X_{i:p}$
- return $C=C_L \cup C_R \cup \{i\}$ as result of current function call

Implementing the algorithm described above will allow for a time complexity of $O(np\log(p))$ where $n$ is
the number of samples, $p$ is the number of columns. The reduction in time complexity is only possible
because of the strong assumption the data set has a hierarchical likelihood behavior. However, that
doesn't hold true for many situations, as it will be seen in more detail in the next chapters,
and the use of this algorithm should done with care.

## Hybrid lgorithm

The hybrid algorithm is a modified version of the hierarchical algorithm, in which it will start searching the
combinations using the hierarchical approach, and if the segments become smaller than a certain threshold,
it will try to find the exact segments with the exact algorithm. The procedure would be as follow:

- let $d$ be the current data set we want to segment
- if the number of columns of $d$ is $p_d < k$, in which $k$ is a predefined threshold, return the set of
  change points calculated by the exact algorithm.
- for each column $i$ in the data set
- compute the total likelihood $l_i = \text{lik}(X_{1:i-1})+\text{lik}(X_{i:p})$ if $i \ne 1$
- find $i$ for which $l_i$ is maximum
- if $l_i < \text{lik}(X_{1:p})$ return empty set as result of current function call
- recursively find the set of change points $C_L$ by calling the algorithm on the left segment $X_{1:i-1}$
- recursively find the set of change points $C_R$ by calling the algorithm on the right segment $X_{i:p}$
- return $C=C_L \cup C_R \cup \{i\}$ as result of current function call

The only difference of this procedure and the hierarchical procedure is the presence of the conditional
step in the beginning of the procedure that tests whether of not to use the hybrid algorithm.
